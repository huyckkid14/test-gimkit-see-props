<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>AI Image Similarity</title>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.16.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>

<style>
body{
  background:#111;
  color:white;
  font-family:Arial;
  text-align:center;
  padding:20px;
}
input{ margin:10px; }
img{
  max-width:200px;
  border:2px solid #444;
  margin:10px;
}
#result{
  font-size:22px;
  margin-top:20px;
}
</style>
</head>
<body>

<h2>AI Image Similarity (Neural Network)</h2>

<input type="file" id="img1Input" accept="image/*">
<input type="file" id="img2Input" accept="image/*">

<div>
  <img id="img1Preview">
  <img id="img2Preview">
</div>

<div id="result">Loading AI model...</div>

<script>
let model;
let img1Ready = false;
let img2Ready = false;

const img1Preview = document.getElementById("img1Preview");
const img2Preview = document.getElementById("img2Preview");
const result = document.getElementById("result");

async function loadModel() {
  model = await mobilenet.load({version:2, alpha:1.0});
  result.textContent = "Model loaded. Upload two images.";
}
loadModel();

function loadImage(input, preview, flagSetter){
  input.addEventListener("change", () => {
    const file = input.files[0];
    if(!file) return;

    const reader = new FileReader();
    reader.onload = () => {
      preview.src = reader.result;
      preview.onload = () => {
        flagSetter(true);
        compareIfReady();
      };
    };
    reader.readAsDataURL(file);
  });
}

function cosineSimilarity(a, b) {
  let dot = 0, normA = 0, normB = 0;
  for (let i = 0; i < a.length; i++) {
    dot += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }
  return dot / (Math.sqrt(normA) * Math.sqrt(normB));
}

async function getEmbedding(img) {
  const tensor = tf.browser.fromPixels(img)
    .resizeNearestNeighbor([224,224])
    .toFloat()
    .expandDims();

  const embedding = model.infer(tensor, true);
  const data = await embedding.data();
  tf.dispose([tensor, embedding]);
  return data;
}

async function compareIfReady() {
  if (!img1Ready || !img2Ready || !model) return;

  result.textContent = "Analyzing images with AI...";

  const emb1 = await getEmbedding(img1Preview);
  const emb2 = await getEmbedding(img2Preview);

  const similarity = cosineSimilarity(emb1, emb2);

  // similarity ranges roughly 0 â†’ 1
  if(similarity > 0.9){
    result.textContent = `Almost identical (${(similarity*100).toFixed(2)}%)`;
    result.style.color = "lime";
  }
  else if(similarity > 0.75){
    result.textContent = `Very similar (${(similarity*100).toFixed(2)}%)`;
    result.style.color = "lightgreen";
  }
  else if(similarity > 0.5){
    result.textContent = `Somewhat similar (${(similarity*100).toFixed(2)}%)`;
    result.style.color = "orange";
  }
  else{
    result.textContent = `Different images (${(similarity*100).toFixed(2)}%)`;
    result.style.color = "red";
  }
}

loadImage(img1Input, img1Preview, v => img1Ready = v);
loadImage(img2Input, img2Preview, v => img2Ready = v);
</script>

</body>
</html>
